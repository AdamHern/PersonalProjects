{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess Images"
      ],
      "metadata": {
        "id": "bh_uBeBy6wKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from tensorflow import data, image, io\n",
        "from tqdm.notebook import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "TjDd0zmcVFgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageChannels = 3\n",
        "maskChannels = 1\n",
        "\n",
        "size = 128\n",
        "imagePath = '/content/drive/MyDrive/DataSets/Roads/Road'\n",
        "maskPath = '/content/drive/MyDrive/DataSets/Roads/Mask'\n",
        "outputPath = '/content/drive/MyDrive/DataSets'\n",
        "\n",
        "imagesData = []\n",
        "filenames = []\n",
        "masksData = []"
      ],
      "metadata": {
        "id": "gr3Wbk45VOsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(os.listdir(imagePath)))\n",
        "print(sorted(os.listdir(maskPath)))"
      ],
      "metadata": {
        "id": "FSPNDYIl6REm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in  tqdm(sorted(os.listdir(imagePath))):\n",
        "  path = os.path.join(imagePath, filename)\n",
        "  img = io.read_file(path)\n",
        "  img = image.decode_png(img, channels = 3)\n",
        "  img = image.resize(img, (size, size))\n",
        "  img = image.convert_image_dtype(img, \"float32\")\n",
        "  imagesData.append(np.asarray(img))\n",
        "\n",
        "imagesData = np.reshape(imagesData, (len(imagesData), size, size, imageChannels))\n",
        "imagesData = imagesData / 255\n",
        "\n",
        "print(\"saving file...\")\n",
        "np.save(os.path.join(outputPath, \"imagesData.npy\"), imagesData)\n",
        "print(\"file saved!\")"
      ],
      "metadata": {
        "id": "FQCHx-Ymc-Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masksData = []\n",
        "\n",
        "for filename in  tqdm(sorted(os.listdir(maskPath))):\n",
        "  path = os.path.join(maskPath, filename)\n",
        "  img = io.read_file(path)\n",
        "  img = image.decode_png(img, channels = maskChannels)\n",
        "  img = image.resize(img, (size, size), method=\"nearest\")\n",
        "  img = image.convert_image_dtype(img, \"uint8\")\n",
        "  masksData.append(np.asarray(img))\n",
        "\n",
        "masksData = np.reshape(masksData, (len(masksData), size, size, maskChannels))\n",
        "masksData = masksData / 255\n",
        "\n",
        "print(\"saving file...\")\n",
        "np.save(os.path.join(outputPath, \"masksData.npy\"), masksData)\n",
        "print(\"file saved!\")"
      ],
      "metadata": {
        "id": "VFYFtZIGFBvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Road Generation"
      ],
      "metadata": {
        "id": "uHjpVuqS69UH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "acL4RDOHIkVb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense, Flatten, LayerNormalization, Activation, ZeroPadding2D, AveragePooling2D, GaussianNoise, UpSampling2D, Conv2D, Conv2DTranspose, BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU, ReLU\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.models import load_model, save_model\n",
        "from keras.datasets.cifar10 import load_data\n",
        "from skimage.transform import resize\n",
        "from keras import initializers, backend\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "from tensorflow import data, image, io\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imageChannels = 3\n",
        "maskChannels = 1\n",
        "\n",
        "size = 128"
      ],
      "metadata": {
        "id": "dBhIaQO2qGZI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masksData = np.load('/content/drive/MyDrive/DataSets/masksData.npy')\n",
        "imagesData = np.load('/content/drive/MyDrive/DataSets/imagesData.npy')"
      ],
      "metadata": {
        "id": "JwUPdU8VI4Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(masksData, imagesData, test_size=0.2, random_state=42)\n",
        "\n",
        "plt.imshow(imagesData[50], interpolation='nearest')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "hUob5OzsWYCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(masksData[50], interpolation='nearest')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "xq9pU2R9MLRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "uI6rtBspWc9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roadModel():\n",
        "  inputs = Input((size, size, maskChannels))\n",
        "\n",
        "  model = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(inputs)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(inputs)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = AveragePooling2D()(model)\n",
        "\n",
        "  model = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = AveragePooling2D()(model)\n",
        "\n",
        "  model = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = AveragePooling2D()(model)\n",
        "\n",
        "  model = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = AveragePooling2D()(model)\n",
        "\n",
        "# -------------------------------------------\n",
        "\n",
        "  model = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "\n",
        "# -------------------------------------------\n",
        "\n",
        "  model = Conv2DTranspose(256, (3, 3),  strides = (2, 2), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "\n",
        "  model = Conv2DTranspose(128, (3, 3), strides = (2, 2), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "\n",
        "  model = Conv2DTranspose(64, (3, 3), strides = (2, 2), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "\n",
        "  model = Conv2DTranspose(32, (3, 3), strides = (2, 2), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "  model = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "  model = LeakyReLU(alpha=0.1)(model)\n",
        "\n",
        "  model = Conv2D(imageChannels, (3, 3), padding='same', activation='tanh')(model)\n",
        "\n",
        "  return Model(inputs, model)"
      ],
      "metadata": {
        "id": "DcpaRHAbWcUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimizer():\n",
        "  return Adam(learning_rate=0.0003, beta_1=0.5)"
      ],
      "metadata": {
        "id": "6qiU89v_m0FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "HX0hyOVOWgPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel():\n",
        "  model = roadModel()\n",
        "  model.summary()\n",
        "  model.compile(optimizer=optimizer(), loss='binary_crossentropy')\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=50, batch_size=16)\n",
        "\n",
        "  model.evaluate(X_test, y_test)\n",
        "\n",
        "  model.save('/content/drive/MyDrive/DataSets/roadModel.keras')\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "5aAQDJ2XWfqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainModel()"
      ],
      "metadata": {
        "id": "XsOsmuRCRxT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def continueTrainModel():\n",
        "  model = load_model('/content/drive/MyDrive/DataSets/roadModel.keras')\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=150, batch_size=16)\n",
        "\n",
        "  model.evaluate(X_test, y_test)\n",
        "\n",
        "  model.save('/content/drive/MyDrive/DataSets/roadModel1.keras')\n",
        "  return model"
      ],
      "metadata": {
        "id": "jNEq9UnGejRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continueTrainModel()"
      ],
      "metadata": {
        "id": "EHBDSHzko5xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# See Results\n",
        "\n"
      ],
      "metadata": {
        "id": "hNkiNIA_77Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testData = []\n",
        "test = io.read_file('/content/drive/MyDrive/DataSets/Roads/RoadTestMask.png')\n",
        "test = image.decode_png(test, channels = 1)\n",
        "test = image.resize(test, (size, size))\n",
        "test = image.convert_image_dtype(test, \"uint8\")\n",
        "testData.append(np.asarray(test))\n",
        "\n",
        "testData = np.reshape(testData, (len(testData), size, size, maskChannels))\n",
        "testData = testData / 255\n",
        "\n",
        "print(\"saving file...\")\n",
        "np.save(os.path.join('/content/drive/MyDrive/DataSets/Roads', \"testData.npy\"), testData)\n",
        "print(\"file saved!\")"
      ],
      "metadata": {
        "id": "t_0VZI3atDvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loadedModel = load_model('/content/drive/MyDrive/DataSets/roadModel1.keras')"
      ],
      "metadata": {
        "id": "R-G1VR28t-8d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(cnt, noise, generator):\n",
        "  image_array = np.full((128, 128, 3), 255, dtype=np.uint8)\n",
        "  generated_images = generator.predict(noise)\n",
        "  generated_images = generated_images\n",
        "  image_count = 0\n",
        "  for row in range(1):\n",
        "    for col in range(1):\n",
        "      r = row * size\n",
        "      c = col * size\n",
        "      image_array[r:r + size, c:c + size] = generated_images[image_count] * 255\n",
        "      image_count += 1\n",
        "  output_path = '/content/drive/MyDrive/DataSets'\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "  filename = os.path.join(output_path, f\"trained-{cnt}.png\")\n",
        "  im = Image.fromarray(image_array)\n",
        "  im.save(filename)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "22iJvIGhzYr-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_images(6, testData, loadedModel)"
      ],
      "metadata": {
        "id": "THy0kKXTzhjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}