{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiYC-5vmDclP"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, LayerNormalization, Activation, ZeroPadding2D, AveragePooling2D, GaussianNoise\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.layers import LeakyReLU, ReLU\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.models import load_model, save_model\n",
        "from keras.datasets.cifar10 import load_data\n",
        "from skimage.transform import resize\n",
        "from keras import initializers, backend\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from progressbar import progressbar\n",
        "import cv2\n",
        "from Augmentor import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiActmocbF-H"
      },
      "outputs": [],
      "source": [
        "training_data = np.load('/content/drive/MyDrive/Art/CPGAN128x128.npy')\n",
        "form = np.load('/content/drive/MyDrive/Art/Form.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmYyIA2w_vin",
        "outputId": "0d01140d-98b1-45e2-c319-0c602c40aadb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18312, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "training_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1hRB6mRCMC4"
      },
      "outputs": [],
      "source": [
        "random_dim = 100\n",
        "PREVIEW_ROWS = 6\n",
        "PREVIEW_COLS = 6\n",
        "PREVIEW_MARGIN = 0\n",
        "SAVE_FREQ = 10\n",
        "IMAGE_SIZE = 128\n",
        "WIDTH = 128\n",
        "HEIGHT = 128\n",
        "CONTROL_SIZE_SQRT = 6\n",
        "CHANNELS = 3\n",
        "EPOCHS =  50000\n",
        "START_DIM = 4\n",
        "\n",
        "FOLDER_PATH = \"/content/drive/MyDrive/PhotoComposition/CPGAN-Images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxu3DNx0nWLH",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "files = []\n",
        "label = 0\n",
        "for folder in tqdm(os.listdir(FOLDER_PATH)):\n",
        "  path = os.path.join(FOLDER_PATH, folder)\n",
        "  for filename in os.listdir(path):\n",
        "    labels.append(label)\n",
        "    files.append(filename)\n",
        "  label += 1\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWVdClg0MukA"
      },
      "outputs": [],
      "source": [
        "def save_images(cnt, noise, generator):\n",
        "  image_array = np.full((PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)), PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3), 255, dtype=np.uint8)\n",
        "  generated_images = generator.predict(noise, verbose = 0)\n",
        "  generated_images = 0.5 * generated_images + 0.5\n",
        "  image_count = 0\n",
        "  for row in range(PREVIEW_ROWS):\n",
        "    for col in range(PREVIEW_COLS):\n",
        "      r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
        "      c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
        "      image_array[r:r + IMAGE_SIZE, c:c + IMAGE_SIZE] = generated_images[image_count] * 255\n",
        "      image_count += 1\n",
        "  output_path = '/content/drive/MyDrive/Art/Outputs/output107'\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "  filename = os.path.join(output_path, f\"trained-{cnt}.png\")\n",
        "  im = Image.fromarray(image_array)\n",
        "  im.save(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1xq7WKxz4lU"
      },
      "outputs": [],
      "source": [
        "def get_optimizer():\n",
        "  return RMSprop(lr = .0001, clipvalue = 1.0, decay = 1e-8)\n",
        "def get_generator():\n",
        "  gen_input = Input(shape=random_dim)\n",
        "  generator = Sequential()\n",
        "\n",
        "  generator.add(Dense(512 * START_DIM * START_DIM, input_dim=random_dim))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "  generator.add(Reshape((START_DIM, START_DIM, 512)))\n",
        "\n",
        "  generator.add(UpSampling2D());\n",
        "  generator.add(Conv2DTranspose(1024, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  generator.add(UpSampling2D());\n",
        "  generator.add(Conv2DTranspose(512, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  generator.add(UpSampling2D());\n",
        "  generator.add(Conv2DTranspose(256, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  generator.add(UpSampling2D());\n",
        "  generator.add(Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  generator.add(UpSampling2D());\n",
        "  generator.add(Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  generator.add(Conv2D(CHANNELS, (4, 4), activation='tanh', padding='same', kernel_initializer='he_normal'))\n",
        "\n",
        "  generated_image = generator(gen_input)\n",
        "\n",
        "  generator.summary()\n",
        "\n",
        "  return Model(gen_input, generated_image)\n",
        "\n",
        "def get_discriminator():\n",
        "  models = []\n",
        "  disc_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
        "  discriminator = Sequential()\n",
        "  # discriminatorClass = Sequential()\n",
        "\n",
        "  discriminator.add(disc_input)\n",
        "\n",
        "  discriminator.add(Conv2D(64, (1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(AveragePooling2D());\n",
        "  discriminator.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(AveragePooling2D());\n",
        "  discriminator.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(AveragePooling2D());\n",
        "  discriminator.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(AveragePooling2D());\n",
        "  discriminator.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(AveragePooling2D());\n",
        "  discriminator.add(Conv2D(1024, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal'))\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  discriminator.add(Flatten())\n",
        "  # discriminatorClass.add(discriminator)\n",
        "\n",
        "  discriminator.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # discriminatorClass.add(Dense(1024))\n",
        "  # discriminatorClass.add(LeakyReLU(0.2))\n",
        "\n",
        "  # discriminatorClass.add(Dense(512))\n",
        "  # discriminatorClass.add(LeakyReLU(0.2))\n",
        "\n",
        "  # discriminatorClass.add(Dense(8, activation='softmax'))\n",
        "\n",
        "  discriminator.summary()\n",
        "\n",
        "  models.append(discriminator(disc_input))\n",
        "  # models.append(discriminatorClass(disc_input))\n",
        "\n",
        "\n",
        "  discriminator = Model(disc_input, models)\n",
        "\n",
        "  optimizer = RMSprop(\n",
        "       lr = .01,\n",
        "       clipvalue = 1.0,\n",
        "       decay = .01/\n",
        "   )\n",
        "  # optimizer = Adam(lr=0.0002, beta_1=0.9)\n",
        "  discriminator.compile(loss=['binary_crossentropy'], optimizer=optimizer)\n",
        "\n",
        "  return discriminator\n",
        "\n",
        "def get_batch_labels(idx):\n",
        "  ID = []\n",
        "  for i in idx:\n",
        "    ID.append(labels[i])\n",
        "  return np.array(ID)\n",
        "\n",
        "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
        "  discriminator.trainable = False\n",
        "  gan_input = Input(shape=(random_dim,))\n",
        "  x = generator(gan_input)\n",
        "  gan_output = discriminator(x)\n",
        "  gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "  gan.compile(loss=['binary_crossentropy'], optimizer=optimizer)\n",
        "\n",
        "  discriminator.trainable = True\n",
        "  return gan\n",
        "\n",
        "X_train = training_data\n",
        "fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, 100))\n",
        "\n",
        "def train(epochs=1, batchSize=128):\n",
        "  batchCount = X_train.shape[0] / batchSize\n",
        "  print(X_train.shape[0])\n",
        "  print('Epochs:', epochs)\n",
        "  print('Batch size:', batchSize)\n",
        "  print('Batches per epoch:', batchCount)\n",
        "\n",
        "  adam = get_optimizer()\n",
        "  generator = get_generator()\n",
        "  # gen_load = load_model('/content/drive/MyDrive/Art/SavedModels/GAN_OUT105-25000-GEN.h5')\n",
        "  discriminator = get_discriminator()\n",
        "  # disc_load = load_model('/content/drive/MyDrive/Art/SavedModels/GAN_OUT105-25000-DISC.h5')\n",
        "\n",
        "  gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
        "\n",
        "  y_real = np.ones((batchSize, 1))\n",
        "  y_fake = np.zeros((batchSize, 1))\n",
        "\n",
        "  for step in tqdm(range(EPOCHS)):\n",
        "    latent_vectors = np.random.normal(size=(batchSize, random_dim))\n",
        "    generated = generator.predict(latent_vectors, verbose = 0)\n",
        "\n",
        "    idx = np.random.randint(0, training_data.shape[0], batchSize)\n",
        "    real = training_data\n",
        "    # real[batchSize - 1] = form[0]\n",
        "\n",
        "    d_loss = discriminator.train_on_batch(real, np.ones((batchSize, 1)) )\n",
        "    d_loss = discriminator.train_on_batch(generated, np.zeros((batchSize, 1)) )\n",
        "\n",
        "    latent_vectors = np.random.normal(size=(batchSize, random_dim))\n",
        "    misleading_targets = np.ones((batchSize, 1))\n",
        "\n",
        "    a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n",
        "\n",
        "    if step % 250 == 0:\n",
        "      save_images(step, fixed_noise, generator)\n",
        "\n",
        "    if step % 5000 == 0 and step != 0:\n",
        "      discriminator.trainable = False\n",
        "      gan.save(f\"/content/drive/MyDrive/Art/SavedModels/GAN_OUT107-{step}-GAN.h5\")\n",
        "      discriminator.trainable = True\n",
        "      generator.save(f\"/content/drive/MyDrive/Art/SavedModels/GAN_OUT107-{step}-GEN.h5\")\n",
        "      discriminator.save(f\"/content/drive/MyDrive/Art/SavedModels/GAN_OUT107-{step}-DISC.h5\")\n",
        "\n",
        "  discriminator.trainable = False\n",
        "  gan.save(f\"/content/drive/MyDrive/Art/SavedModels/GAN_OUT107-{step}-GAN.h5\")\n",
        "  discriminator.trainable = True\n",
        "  generator.save(f\"/content/drive/MyDrive/Art/SavedModels/GAN_OUT107-{step}-GEN.h5\")\n",
        "  discriminator.save(f\"/content/drive/MyDrive/Art/SavedModels/GAN_OUT107-{step}-DISC.h5\")\n",
        "  print(\"Saved Model!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRZjbi7kznML"
      },
      "outputs": [],
      "source": [
        "train(5000, 32)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}